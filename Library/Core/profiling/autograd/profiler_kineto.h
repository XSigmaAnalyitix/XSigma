#pragma once

#include <set>
#include <string>
#include <vector>

#include "profiling/profiler/api.h"
#include "profiling/profiler/events.h"
#include "profiling/profiler/stubs/base.h"
#include "profiling/profiler/util.h"

namespace xsigma
{
constexpr bool hasCUDA()
{
    return XSIGMA_HAS_CUDA == 1;
}

namespace profiler::impl
{
struct Result;
namespace kineto
{
struct ActivityTraceWrapper;
}  // namespace kineto
}  // namespace profiler::impl

namespace autograd::profiler
{
using experimental_event_t = std::shared_ptr<xsigma::profiler::impl::Result>;
using extra_meta_t         = std::unordered_map<std::string, std::string>;

struct XSIGMA_VISIBILITY KinetoEvent
{
    XSIGMA_API KinetoEvent(
        const std::shared_ptr<const xsigma::profiler::impl::Result>& /*result*/,
        const bool verbose);

    XSIGMA_API uint64_t startThreadId() const;
    XSIGMA_API uint64_t endThreadId() const;
    XSIGMA_API uint8_t  activityType() const;
    XSIGMA_API uint64_t fwdThreadId() const;
    XSIGMA_API bool     hasShapes() const;
    XSIGMA_API const xsigma::array_ref<std::vector<int64_t>> shapes() const;
    XSIGMA_API bool                                          hasTypes() const;
    XSIGMA_API const xsigma::array_ref<std::string> dtypes() const;
    XSIGMA_API bool                                 hasConcreteInputs() const;
    XSIGMA_API const xsigma::array_ref<xsigma::IValue> concreteInputs() const;
    XSIGMA_API bool                                    hasKwinputs() const;
    XSIGMA_API bool                                    isHiddenEvent() const;
    XSIGMA_API const std::unordered_map<std::string, xsigma::IValue> kwinputs() const;
    XSIGMA_API uint64_t                                              flops() const;
    XSIGMA_API int64_t                                               sequenceNr() const;
    XSIGMA_API bool                                                  hasStack() const;
    XSIGMA_API const xsigma::array_ref<std::string> stack() const;
    XSIGMA_API uint8_t                              scope() const;
    XSIGMA_API bool                                 hasModuleHierarchy() const;
    XSIGMA_API const xsigma::array_ref<std::string> moduleHierarchy() const;
    XSIGMA_API int64_t                              debugHandle() const;
    XSIGMA_API std::string name() const;
    XSIGMA_API std::string overload_name() const;
    XSIGMA_API xsigma::device_enum deviceType() const;
    XSIGMA_API int                 deviceIndex() const;
    XSIGMA_API int64_t             nBytes() const;
    XSIGMA_API uint64_t            startNs() const;
    XSIGMA_API uint64_t            endNs() const;
    XSIGMA_API uint64_t            durationNs() const;
    XSIGMA_API bool                isAsync() const;
    XSIGMA_API uint64_t            correlationId() const;
    XSIGMA_API uint64_t            linkedCorrelationId() const;
    XSIGMA_API int64_t             deviceResourceId() const;
    XSIGMA_API std::string  backend() const;
    XSIGMA_API bool         isPythonFunction() const;
    XSIGMA_API int64_t      cudaElapsedUs() const;
    XSIGMA_API int64_t      privateuse1ElapsedUs() const;
    XSIGMA_API void         getPerfEventCounters(xsigma::profiler::perf_counters_t& /*in*/) const;
    XSIGMA_API extra_meta_t extraMeta() const;
    XSIGMA_API std::string metadataJson() const;

private:
    xsigma::profiler::impl::ProfilerVoidEventStub fallbackStart() const;
    xsigma::profiler::impl::ProfilerVoidEventStub fallbackEnd() const;

    std::shared_ptr<const xsigma::profiler::impl::Result> result_;
    std::vector<std::string>                              python_stack_;

    // Copy fields from result so we can return ArrayRefs.
    std::vector<std::vector<int64_t>>               shapes_;
    std::vector<std::string>                        dtypes_;
    std::vector<xsigma::IValue>                     concrete_inputs_;
    std::unordered_map<std::string, xsigma::IValue> kwinputs_;
};

// Consolidating events returned directly from Kineto
// with events manually created by us (e.g. start/stop marks,
// memory allocation events)
struct XSIGMA_VISIBILITY ProfilerResult
{
    XSIGMA_API ProfilerResult();
    XSIGMA_API ProfilerResult(
        uint64_t                                                                start_time,
        std::vector<KinetoEvent>                                                events,
        std::unique_ptr<xsigma::profiler::impl::kineto::ActivityTraceWrapper>&& trace,
        std::vector<experimental_event_t>&&                                     event_tree);
    XSIGMA_API ~ProfilerResult();

    uint64_t trace_start_ns() const { return trace_start_ns_; }

    const std::vector<KinetoEvent>& events() const { return events_; }

    const std::vector<experimental_event_t>& event_tree() const { return event_tree_; }

    void save(const std::string& path);

private:
    uint64_t                                                              trace_start_ns_ = 0;
    std::vector<KinetoEvent>                                              events_;
    std::unique_ptr<xsigma::profiler::impl::kineto::ActivityTraceWrapper> trace_;
    std::vector<experimental_event_t>                                     event_tree_;
};

/*
 * This API is used by backends to record latency of events that
 * happened in the backend but were not visible to pytorch runtime.
 * For example, if part of the model is lowered to a dsp backend, then
 * the execution of that part of the model is delegated to the backend.
 * When backend finishes execution it has an option to provide profiling
 * information (latency only at the moment) corresponding to different operators
 * that were executed in the backend.
 * When such events are recorded by backend using this API, the event
 * records will be collected by active kineto profiler. If no kineto profiler
 * is active then the event is ignored.
 * This provides us with a way to generate all the profiling information
 * for a model regardless of where model (or part of it) executed.
 * @param start_time_us: start time in us of the event
 * @param end_time_us: end time in us of the event
 * @param debug_handle: debug handle to correlate this event/op with
 * model level module/source information
 * @param scope: scope of the event, e.g. LITE_INTERPRETER, RECORD_FN etc.
 * @param event_name: name of the event, e.g. op name
 * @param backend_name: name of the backend where the event took place.
 */
XSIGMA_API void reportBackendEventToActiveKinetoProfiler(
    const int64_t             start_time_us,
    const int64_t             end_time_us,
    const int64_t             debug_handle,
    const xsigma::RecordScope scope,
    const std::string&        event_name,
    const std::string&        backend_name);

XSIGMA_API void enableProfiler(
    const xsigma::profiler::impl::ProfilerConfig&         config,
    const std::set<xsigma::profiler::impl::ActivityType>& activities,
    const std::unordered_set<xsigma::RecordScope>&        scopes = {});

/*
 * Same as enableProfiler but with callback to do post-processing of
 * KinetoEvents.
 * enableProfilerWithEventPostProcess enables profiler to capture
 * specified activities, with specified RecordFunction scope, if any.
 * Additionally, it takes a functor that does in-place post processing of
 * events, e.g. populate stack trace or module hierarchy information lazily
 * using debug_handle.
 * Example usage is with lite interpreter that has recording scope of
 * LITE_INTERPRETER. In this case lite interpreter runtime, records debug
 * handles in RecordFunction, along with other information. Debug handles are
 * eventually passed down to KinetoEvent and recorded as part of the event.
 * KinetoEdgeCPUProfiler, in xsigma/csrc/jit/mobile/profiler_edge.cpp, enables
 * profiler using post-processing callback, via
 * enableProfilerWithEventPostProcess, that takes these debug handles and
 * generates stack trace and module hierarchy information, once profiling is
 * done.
 */
using post_process_t = std::function<void(
    /*debug_handle */ int64_t,
    /*jit_stack    */ std::vector<std::string>&,
    /*jit_modules  */ std::vector<std::string>&)>;
XSIGMA_API void enableProfilerWithEventPostProcess(
    const xsigma::profiler::impl::ProfilerConfig&         config,
    const std::set<xsigma::profiler::impl::ActivityType>& activities,
    post_process_t&&                                      cb,
    const std::unordered_set<xsigma::RecordScope>&        scopes = {});

XSIGMA_API std::unique_ptr<ProfilerResult> disableProfiler();

XSIGMA_API void prepareProfiler(
    const xsigma::profiler::impl::ProfilerConfig&         config,
    const std::set<xsigma::profiler::impl::ActivityType>& activities);

XSIGMA_API void toggleCollectionDynamic(
    const bool enable, const std::set<xsigma::profiler::impl::ActivityType>& activities);

XSIGMA_API void startMemoryProfile();
XSIGMA_API void stopMemoryProfile();
XSIGMA_API void exportMemoryProfile(const std::string& path);

/**
 * When a C++ thread really has no control over how the profiler was enabled,
 * for example, by some unreachable Python code, it can call these functions
 * to test/join/unjoin itself into the collection set of a profiler, if any.
 * Without calling these functions, the symptom may be "not seeing GPU events
 * from some child C++ threads". This is an example on how to use them,
 *
 *    using namespace xsigma::autograd::profiler;
 *    bool enabled = isProfilerEnabledInMainThread();
 *    if (enabled != saved_enabled_state) {
 *      if (enabled) {
 *        enableProfilerInChildThread();
 *      } else {
 *        disableProfilerInChildThread();
 *      }
 *      saved_enabled_state = enabled;
 *    }
 */
XSIGMA_API bool isProfilerEnabledInMainThread();
XSIGMA_API void enableProfilerInChildThread();
XSIGMA_API void disableProfilerInChildThread();

}  // namespace autograd::profiler

namespace profiler::impl
{

// Experimental.
XSIGMA_API void _reportVulkanEventToProfiler(vulkan_id_t id);

}  // namespace profiler::impl

}  // namespace xsigma
